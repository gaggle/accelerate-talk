<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>reveal.js</title>

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/serif.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement('link')
      link.rel = 'stylesheet'
      link.type = 'text/css'
      link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css'
      document.getElementsByTagName('head')[0].appendChild(link)
    </script>

    <style>
        .reveal section img {
            border: none;
            box-shadow: none;
            margin: 0;
        }
    </style>
</head>
<body>
<div class="reveal">
    <div class="slides">

        <section data-notes="So, a new book came out recently, and it's really full of insights into software development. I want to speak to you about what it says, that we can do, to work smarter, and how it uses a very scientific approach to measure how effectively software teams create value.
And the data really is quite remarkable: It identifies that the best teams are <b>twice<b> as likely to exceed company goals like, profitability, productivity.. customer satisfaction. Twice as likely.
So, we should really want about this performance stuff, right?

The book is called &#34;Accelerate">
            <h2>The science of software development</h2>
            <h4>Practical tips for working smarter</h4>
        </section>

        <section data-notes="the science of lean and devops; building high performing organizations.&#34;
And you may recognize the authors, they're really well-known names in the DevOps community.
But, so, my first thought was, what is the science here? What does &#34;high performing&#34; mean? How does this relate to me?
And to answer that we have to first understand a bit about the data, and how its analyzed, and then we can link it up to how we work.

Okay?">
            <img class="stretch" data-src="static/accelerate-cover.png" alt="Cover of Accelerate book"/>
        </section>

        <section>

            <section
                    data-notes="So, the research is very robust, it's based on surveys sent to a very large number of people, around 20 to 30 <b>thousand</b> respondents, every year for 4 years, from all around the">
                …
            </section>

            <section
                    data-notes="world. Those participants are from all kinds of industries, every size of companies, all kinds of different processes.
The responders are people and organizations familiar enough with the term &#34;DevOps&#34; to answer the surveys, so, in all this data basically everyone knows about DevOps topics like infrastructure-as-code, and continuous integration.
The kind of work we do fits right into all this. The kind of product we make, our size, our technology, our process, it's all right in the middle of all this. This is definitely our crowd.

But what did they find?">
                <img data-src="static/demographics-survey-map-2018.png"
                     alt="Geographical map showing the entire world was surveyed"/>
            </section>

        </section>

        <section>

            <section data-notes="First let's decode what's meant with &#34;high performing&#34;. Why should we believe that their idea of good is worth pursuing?

So, measuring performance of software teams has a troubled past.
There were early attempts of measuring lines of code, or tracking how busy people are. But that's too naive, lines of code and busyness do not tell you how well the team delivers value.
Or there was using team velocity, so, the more story-points burnt the better, but that doesn't work, in part because the teams end up pitted against each other, because helping another team can hurt your own velocity.
So, informed by past attempts, this research is careful to focus on measuring globally positive outcomes. That is, outcomes have to be good for the entire organisation.
The entire book really is about scientifically identifying which things we, in software teams, do, that leads to good performance for the company. By measuring how teams work, and how their companies perform, statistical models can be made that shows how certain variables control certain outcomes.">
                …
            </section>

            <section>
                <h2 data-notes="Software Delivery Performance model.
Based on how teams and companies perform, this research identifies four important team-metrics that links to company performance. And they're actually surprisingly easy to go through.

The first one is">Software Delivery Performance</h2>
            </section>
            <section data-notes="delivery lead time, that's how long it takes for code to get to production. Shorter is better, because, this is how fast we deliver value to our customers.
Concretely the survey asked how long it takes from code committed, to code successfully running in production, and participants had to choose one of these options:">
                <h2>Delivery lead time</h2>
                <ul class="fragment" data-notes="Alright? That's all there is to delivery lead time.

The second performance metric, that is linked to company performance, is">
                    <li>Less than one hour</li>
                    <li>Less than one day</li>
                    <li>Between one day and one week</li>
                    <li>Between one week and one month</li>
                    <li>Between one month and six months</li>
                    <li>More than six months</li>
                </ul>
            </section>

            <section data-notes="deployment frequency. More frequent deploys reduces risk because each deploy has less features batched into them, and that removes those huge dumps of features that all have to go live at once.

Deployment here means deployment to production. Participants were asked how often they deploy code to their primary service, and had to chose one of these answers:">
                <h2>Deployment frequency</h2>
                <ul class="fragment"
                    data-notes="Okay, so far so good, lead time and deployment frequency captures performance tempo. But what if going fast comes at the expense of stability? We also need to measure">
                    <li>On demand (multiple deploys per day)</li>
                    <li>Between once per hour and once per day</li>
                    <li>Between once per day and onc per week</li>
                    <li>Between once per week and onc per month</li>
                    <li>Between once per month and once every six months</li>
                    <li>Fewer than once every six months</li>
                </ul>
            </section>

            <section
                    data-notes="quality. But.., what's quality? A classic reliability metric is to measure &#34;how much time between failures&#34;, but the thing with software is that it's so complex and always changing that failure is really inevitable.

So the more relevant question becomes &#34;How quickly is service restored?&#34;. And <b>that</b> is a widely used metric known as">
                <h2>Quality</h2>
            </section>

            <section>
                <h2 data-notes="mean time to restore.
So, participants were asked how long it generally takes to restore service when an incident occurs, like an unplanned outage or service impairment. And they had to pick one of these options">
                    Mean Time To Restore
                </h2>
                <ul class="fragment" data-notes="And the last to go through is">
                    <li>Less than one hour</li>
                    <li>Less than one day</li>
                    <li>Between one day and one week</li>
                    <li>Between one week and one month</li>
                    <li>Between one month and six months</li>
                    <li>More than six months</li>
                </ul>
            </section>

            <section data-notes="change fail percentage. This is tracking how many deploy or configuration changes causes a failure. The question asked was what percentage of all changes to a system result in degraded service?

So, y'know, any time we have to patch, or roll forward, or apply a hot fix, or redo work, that all counts towards this percentage.">
                <h2>Change fail percentage</h2>
            </section>

            <section data-notes="And that's it, those are the four performance metrics..
Now, you may be thinking that these metrics don't seem to capture the entire software development process. Aren't they too simplistic? And, yeah, they are simple, no research perfectly captures every details, in fact it shouldn't, right? It'd be way too complex. But these four metrics are the culmination of a lot of hard work to identify which things can be reliably measured <b>and</b> reliably affects business performance.
In the intro I said high performing teams are twice as likely to exceed company goals, and that was identified by three tiers of software teams that the researchers identified: The High, medium, and lower performers. To be honest I was kind of provoked by those names at first, because they sounded so arbitrary. But the groups are actually identified by an algorithm that has no understanding of &#34;good&#34; or &#34;bad&#34; responses. It's just an algorithm that finds unbiased groups in a bunch of responses. And it found three groups that the researchers compared to how their respective companies performed, and then labelled them High, Medium, and Low performers.">
                <img data-src="static/software-delivery-performance.png"
                     alt="List of the four performance metrics"/>
            </section>

            <section data-notes="And we can see here that high performers have multiple deploys per day, changes go to production in less than an hour, they restore service outages in less than an hour, and they have a low change failure rate.

Perhaps surprisingly this shows that high performers do not trade off stability and quality. High performers do better in all measurements.

And yet, how often do we hear or say that we can move faster by trading off quality? The data shows that's just not the case. Next time we hear the argument to cut a corner to go fast, think about this finding, remember that ">
                <img data-src="static/software-delivery-performance-for-2017.png"
                     alt="Table showing performance metrics for 2017"/>
            </section>

            <section data-notes="moving fast means high stability and quality.
Is that counter-intuitive to hear? I think for some it is, but even if you were already on-board with this I think the science and the hard data to back up that claim is new.

At this point I wondered, how do we rate?">
                <h4>Finding 0</h4>
                <h2>Moving fast means high stability and quality</h2>
            </section>

            <section data-notes="And, well, I'm not sure we have all the numbers.
We can probably answer Deployment frequency right? PFG is kind of our main product, where'd you say it lands?
And Lead time?
Mean time to recovery? We had some recent incidents that lasted several days, right? Really looking forward to seeing how much we move the needle on this metric as we go through our stability drive.
And Change failure rate?

Just imagine <b>if</b> we could all agree that we actually do want to track our performance. What if each team measured these metrics, and we all discussed them together? I think that would provide a lot of insights, by quantifying the successes of certain ways each team works. One team might improve, say, deployment frequency above the others, and we could all learn from that. We'd inspire, and be inspired by, each other. I think we could really help each other to become more high performing, using the shared language of this performance model.">
                <img data-src="static/software-delivery-performance-for-2017.png"
                     alt="Table showing performance metrics for 2017"/>
            </section>

        </section>

        <section>

            <section data-notes="Okay, so, I think that was already pretty interesting. But I want to go deeper, because there are more concrete and actionable findings to talk about.
But.. to get there we have to understand a bit more about these statistical constructs. We've gone over how to measure software delivery performance, and how the data shows that software delivery performance <b>causes</b> organizational performance. That's shown like">
                …
            </section>

            <section
                    data-notes="this. The arrow here is to show that improving software delivery, causes organizational performance to also increase. And then you might ask, what impacts software delivery performance?
Well, more than one thing does, but I'll just cover one of its inputs so we don't spend hours on just this part of the research. The research found that an important driver of software delivery is">
                <img data-src="static/software-delivery-performance-drives-organizational-performance.png"
                     alt=""/>
            </section>

            <section
                    data-notes="culture. But.. what's culture?, that's a word with many meanings.. What we need is more specifically known as">
                <h2>Culture</h2>
            </section>

            <section>
                <h2 data-notes="organizational culture. And that makes sense, because agile and DevOps have always been known to be as much about cultural changes as about technical changes.
There is a lot of detail to this topic, but I want to skip right to the end, where, after a lot of analysis, a model was chosen called the">
                    Organizational Culture</h2>
            </section>

            <section
                    data-notes="Westrum Culture model. That's an established and well-known model in the social sciences, it's been around for like 15 years and had its origins in some pretty serious industries like health-care and aviation. It basically boils down to about half a dozen statements that participants rate their agreement to. So you'd rate how much you agree to, something like, quote, &#34;On my team, responsibilities are shared&#34;.
This model then uses some specific terminology that Dr. Westrum came up with. He identified three types of organizational cultures,">
                <h2>Westrum Culture model</h2>
            </section>

            <section data-notes="calling them Pathological, Bureaucratic, and Generative cultures. Each of these link to organizational performance in different ways, and for now just know that Generative culture is the good one, that's where we share knowledge really well, accomplish goals, and on doing so well. The other cultures have negative traits, that detracts from a company's performance.

And the amazing thing with this Westrum culture model, is that it shows that culture <b>predicts</b> organizational performance. Okay? He showed that a generative culture <b>causes</b> better org performance. I personally resisted that a bit when I first read it, but there are whitepapers and research to back it up. What I've read, boils down to a lot of case studies and statistics that show how changes to culture really does affect the companies, and that this model captures those changes.
So, the researchers adopted this model, and one thing they found is that in software, this Culture model actually drives">
                <img data-src="static/westrums-typology-of-organizational-culture.png"
                     alt=""/>
            </section>
            <section
                    data-notes="software delivery performance. So if we can improve culture, we improve software delivery performance. I guess if we work better together we improve our software delivery..
And that isn't exactly shocking, right? I'd be surprised if better knowledge sharing <b>didn't</b> allow us to deliver better. I know the conclusions so far aren't exactly earth-shattering, I'm building up to those those :), but I didn't know these concepts could be analyzed and quantified so.. succinctly. These kinds of predictive relationships are really powerful, because with them, we don't have to second-guess ourselves on every big-picture question we wonder about. Based on all those tens of thousands of data-points we can see that to work more effectively we need to work on our culture, because that improves everything downstream.
So the obvious question is: What affects culture?

Well, all that survey data found another very interesting predictive relationship: That Continuous Delivery">
                <img data-src="static/westrum-organizational-cultures-drives-software-delivery-performance.png"
                     alt="Graph showing Westrum culture impacts software delivery and organizational performance"/>
            </section>

            <section
                    data-notes="improves culture. Okay, so, what improves continuous delivery then? Why don't we just chase this all the way down?
And we will, that's really what this whole talk is about :). I just need us to agree on what we're doing here, that we're coupling these constructs together, to form a statistically valid argument that">
                <img data-src="static/westrum-organizational-cultures-drivers-highlight.png"
                     alt="Graph showing Continuous Delivery impacts Westrum culture"/>
            </section>

            <section data-notes="continuous delivery causes better organizational performance!
Wow! Except.. heh, okay, again, we.. actually already knew that, right? :) The whole software industry has been chasing continuous delivery for, like, the last decade. Things like test automation, and monitoring, and infrastructure-as-code, they're all part of CD, and it sure would be surprising if everyone was doing it, and we'd find that it <b>didn't</b> affect org performance.
But that's how it is with science, it often verifies knowledge we already know. But the point is we now have these these models powered by real numbers, and we can look to them to explain how we can impact them in the most optimal way.
Because what impacts continuous delivery are very concrete things we can do in our daily work.">
                <img data-src="static/westrum-organizational-cultures-drivers-and-outcomes-highlight.png"
                     alt="Graph showing Continuous Delivery and Lean Management impacts performance"/>
            </section>

        </section>

        <section>

            <section
                    data-notes="Okay, now we're ready to talk specifics. But all that context was important, because it's what separates these findings from just being empty sentences. When we say &#34;fast means high stability and quality&#34;, that's a really powerful statement, because it's built on data and validated models. It's a scientific statement.
Of course, it's, not like every word of this is, some holy truth.. At the end of the day this is social science and statistics so, there is a limit to the precision. And these models and the data can and should be criticised. But when we do criticise, we must also take into account the thousands of data-points that underpin all this; all the careful use of">
                …
            </section>

            <section data-notes="science.
By going from the outside in, we've taken the journey to understand the full picture of these insights. First we learned that software delivery performance causes high organizational performance, but that was very abstract, it's hard to see how exactly that relates to my work. But by drilling further and further down we've gotten more and more concrete. Some of you probably already have some pretty good ideas of what goes into the Continuous Delivery model.

Okay, so, at its most practical, the book identifies 24 specific technical and managerial practices that impacts organizational performance. I can't go through all capabilities today, but I've picked two examples that relate directly to how we work. They're both technical capabilities, because, we're mostly technical people here. The first one is kind of a low-hanging fruit, but a really interesting one I think, and the other is more challenging, both technically and politically. But the other 22 capabilities are really good too, they focus on process, or management, security, or.. architecture, and more. They're all well worth looking into.

But, lets go for that first one. First we have">
                <img data-src="static/analytics-feedback-loop.png"
                     alt=""/>
            </section>

            <section data-notes="trunk based development. Aka master-based development. It's the way of working that is the opposite of long-lived feature branches.
The data is really clear on this: High performing teams have fewer than 3 active branches at any time, their branches have very short lifespans of less than a day, and the teams never have code freeze periods. These results are completely independent of team size, org size, or industry.

Trunk based development is strongly correlated with Continuous Delivery, and so we know that, that means statistically the company should do better, if we adopt this.

Is that surprising? Certainly the science here was new to me. One theory for why long lived branches should be avoided, is that they discourage small refactorings, because there are always big changes on the horizon.
As a developer I understand this can be uncomfortable to hear, and actually the unbridled clarity of this finding is almost annoying, the researchers are so clear in their conclusion that it can kind of be off-putting. I know some imagine that this way of working can't possibly work, that surely you'll be stuck in conflict-hell with this approach. But I made this switch in my last company, and it just.. worked. And the same for thousands of others, as seen by this research. So the statistics speaks clearly, that we must either commit to trunk, or create no more than 3 active branches per team, and let them live no longer than a single day.

Okay? Food for thought, for some of us, I think.

Let's try one more. Let's talk about">
                <h4>Finding 1</h4>
                <h2>Trunk based development</h2>
            </section>

            <section data-notes="version control. Of all production artifacts. Version control has a very strong correlation to continuous delivery.

Now, maybe saying version control sounds innocent, but recall that all of our database is really not versioned. And what about any servers or services that you wouldn't want to lose, because they have special changes applied directly to them?
The research identifies a whole set of things that are important to store in version control, because doing so ultimately affect the continuous delivery model. The things to store are: All production artifacts, all application code, all application and system configurations, and all scripts for building and configuring the environment. All of these strongly correlate to continuous delivery, so if we adopt these findings we'll have a great impact on software delivery and org-performance.
In fact the data surprised me, by showing that it is not the <b>application</b> code that's most critical to version, it's actually the <b>configuration</b> code that has the most impact.

But why? Why is this so important? I'm sure we can all agree version control <b>is</b> important for software delivery, I mean, there's a reason we don't store all our code in a shared folder, and upload the latest build straight to an FTP site right? But why is it so important that no infrastructure be built by hand? Why must databases be based on versioned code? Why can't we mess with AWS resources directly, or edit some services in a GUI?
And you know what? I don't think anyone knows. I mean, like, nobody knows for sure. There's no physical law to discover here, there's no ultimate truth to uncover. We can simply look at the facts we have, which is that measured across all those tens of thousands of responders, those that adopted version control of all production artifacts got better at software delivery, and thus increased their organizational performance.
Imagine we took this finding to heart, imagine we re-tooled our database, with all its configuration, its environment, its details, everything captured in version control. We could run that code to make us a new database in a different environment. We could test changes in isolation, instead of directly in production. No more having to fear that every change catastrophically loses production data! No more editing a select and it goes live the second its saved.

I think we intuitively know a lot of this, but this research really validates that this has a huge impact on organizational performance. With this data we can see that getting our systems into version control isn't just some technical niceity. We're leaving money on the table, until we tackle this. Because this is one the road to becoming high performers.
<pause>
So">
                <div>
                    <h4>Finding 2</h4>
                    <h2>Version control</h2>
                </div>
            </section>

            <section data-notes="those are all we have time for today, but I think it's been a lot to take in. If you're interested to hear about the other findings, then, let's meet up. Maybe there's even enough for another talk.. just, tell me, if you would be interested in that.

I think it's worth saying again that these findings are only from four years of research, so, of course it's worth discussing how each model and finding fits into our context. But a lot of this is also relatively simple to try, they're practical things we can do and then see how they work for us. I don't advocate that we must blindly adopt whatever it says in this book, but.. the scientific mindset <b>is</b> one I think we should pay a lot of attention to.

Because it's by measuring how we work, that we can introduce changes and see their impact. And if we do that, and we use it to continuously improve ourselves, to continuously tweak how we work to become ever more effective, then we <b>will</b> go all the way to the top.
The capabilities identified by this research involves everyone, I know today I only talked about technical findings, but the full set involves leadership, management, sales, support, everyone. We should all involve ourselves in this.

It is totally in our power to make these changes, we just have to grab the opportunity.

Thank you :), now, I'd love to hear which questions you have for me.">
                <h2>Findings</h2>
                <ol start="0">
                    <li>Moving <strong>fast means high stability and quality</strong></li>
                    <li>Always do <strong>trunk based development</strong></li>
                    <li>Version control… <strong>everything!</strong></li>
                </ol>
            </section>

        </section>

        <section>
            <img data-src="static/extras/all-relationships.png" alt="Graph showing all relationships"/>
        </section>

        <section>
            <section>
                <h4>Finding 3</h4>
                <h2>Acceptance tests</h2>
                <h4 class="fragment">Primarily developed<br/>and maintained <u>by developers</u></h4>
            </section>
        </section>
    </div>
</div>

<script src="lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>

<script>
  // More info about config & dependencies:
  // - https://github.com/hakimel/reveal.js#configuration
  // - https://github.com/hakimel/reveal.js#dependencies
  Reveal.initialize({
    dependencies: [
      {src: 'plugin/markdown/marked.js'},
      {src: 'plugin/markdown/markdown.js'},
      {src: 'plugin/notes/notes.js', async: true},
      {src: 'plugin/highlight/highlight.js', async: true, callback: function () { hljs.initHighlightingOnLoad() }},
      {src: 'plugin/zoom-js/zoom.js', async: true},
    ]
  })
</script>

<script>
  Reveal.addEventListener('fragmentshown', function (event) {
    if (event.fragment.classList.contains('remove-item')) {
      document.getElementById(event.fragment.dataset.remove)
        .classList.add('removed-item')
    }
  })
  Reveal.addEventListener('fragmenthidden', function (event) {
    if (event.fragment.classList.contains('remove-item')) {
      document.getElementById(event.fragment.dataset.remove)
        .classList.remove('removed-item')
    }
  })
</script>
</body>
</html>
